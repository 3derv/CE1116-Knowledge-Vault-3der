---
Fecha de creación: 2025-09-02 19:11
Fecha de Modificación: 2025-09-02 19:11
tags:
  - IA
Tema: inteligencia-artificial
---


## 📚 Idea/Concepto 

Los embeddings es una técnica de procesamiento de lenguaje humano que lo convierte en representaciones vectoriales aprendidas de tokens codificados con su significado semántico. Son parámetros ajustables que han sido aprendidos y ajustados durante la fase de entrenamiento del modelo. Su dimensionalidad es un hiperparámetro que impacta en la riqueza semántica que va a poder ajustar. Esto permite que las computadoras puedan procesar las palabras como datos y poder aplicar matemática sobre ellas. La codificación posicional se suman a los embeddings, no son parte intrínseca de este. En arquitecturas como los Transformers, estos embeddings iniciales son refinados dinámicamente por los mecanismos de autoatención, permitiendo que cada token incorpore información contextual rica de otros tokens en la secuencia.
## 📌 Puntos Claves (Opcional)
- 

## 🔗 Connections
- [[ ]]

## 💡 Personal Insight (Opcional)
- 
## 🧾 Recursos (Opcional)
- 